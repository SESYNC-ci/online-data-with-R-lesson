---
---

## Requests

That "http" at the beginning of the URL for a possible data source is
a protocol---an understanding between a client and a server about how
to communicate. The client does not have to be a web browser, so long
as it knows the protocol. After all, [servers exist to
serve](https://xkcd.com/869/).

===

The [requests](){:.pylib} package provides a simple interface to
issuing HTTP requests and handling the response. Here's an example
using an [XKCD comic](https://xkcd.com/869/).

```{python, handout = 0}
import requests

response = requests.get('https://xkcd.com/869')
response
```

===

The response is still binary. It takes a browser-like parser to
translate the raw content into an HTML
document. [BeautifulSoup](){:.pylib} does a fair job, while making no
attempt to "render" a human-readable page.

```{python, handout = 0}
from bs4 import BeautifulSoup

doc = BeautifulSoup(response.text, 'lxml')
'\n'.join(doc.prettify().splitlines()[0:10])
```

===

Searching the document for desired content is the hard part. This search
uses a CSS query to find the image below a section of the document with
attribute `id = comic`.

```{python, handout = 0}
img = doc.select('#comic > img')
img
```

===

It makes sense to query by CSS if the content being scraped always appears
the same in a browser; stylesheets are separate from delivered content.

```{python, handout = 0}
img = doc.select_one('#comic > img')
img['title']
```

===

## Was that so bad?

Pages designed for humans are increasingly harder to parse programmatically.

- Servers provide different responses based on client "metadata"
- JavaScript often needs to be executed by the client
- The HTML `<table>` is drifting into obscurity (mostly for the better)

===

## HTML Tables

Sites with easilly accessible html tables nowadays may be specifically
geared toward non-human agents. The US Census provides some
documentation for their data services in a massive table:

<https://api.census.gov/data/2017/acs/acs5/variables.html>

===

```{python, handout = 0}
import pandas as pd

vars = (
  pd
  .read_html('https://api.census.gov/data/2017/acs/acs5/variables.html')
  .pop()
)
vars.head()
```

===

We can use our data manipulation tools to search this unwieldy
documentation for variables of interest.

```{python, handout = 0}
idx = (
  vars['Label']
  .str
  .contains('Median household income')
)
vars.loc[idx, ['Name', 'Label']]
```
