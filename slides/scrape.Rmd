---
---

## Requests

That "http" at the beginning of the URL for a possible data source is
a protocol---an understanding between a client and a server about how
to communicate. The client does not have to be a web browser, so long
as it knows the protocol. After all, [servers exist to
serve](https://xkcd.com/869/).

===

The [httr](){:.rlib} package provides a simple interface to
issuing HTTP requests and handling the response. Here's an example
using an [XKCD comic](https://xkcd.com/869/).

```{r, handout = 0}
library(httr)

response <- GET('https://xkcd.com/869')
response
```

===

The response is still binary. It takes a browser-like parser to
translate the raw content into an HTML document. 
[rvest](){:.rlib}, a (bad) pun on "harvest" because it harvests
the content of Web pages, does a fair job, while making no
attempt to "render" a human-readable page. The [htmltidy]{:.rlib}
package can be used to display an easier-to-read version with indentations 
and line breaks in your Viewer pane.

```{r, handout = 0}
library(rvest) 
library(htmltidy)

doc <- read_html(response)
html_view(doc)
```

===

Searching the document for desired content is the hard part. This search
uses a CSS query to find the image below a section of the document with
attribute `id = comic`.

```{r, handout = 0}
img <- doc %>%
  html_nodes('#comic > img') 
img

```

===

It is possible to query by CSS for a single element and extract
attributes such as the image title.

```{r, handout = 0}
img <- doc %>%
  html_node('#comic > img') 

img_attrs <- img %>%
  html_attrs()

img_attrs['title']
```

===

## Was that so bad?

Pages designed for humans are increasingly harder to parse programmatically.

- Servers provide different responses based on client "metadata"
- JavaScript often needs to be executed by the client
- The HTML `<table>` is drifting into obscurity (mostly for the better)

===

## HTML Tables

Sites with easily accessible html tables nowadays may be specifically
intended to be parsed programmatically, rather than browsed by a human reader.
The US Census provides some documentation for their data services in a massive table:

<https://api.census.gov/data/2017/acs/acs5/variables.html>

===

Set `fill = TRUE` when you convert the html table into an R 
data frame, so that inconsistent numbers of columns in each row
are filled in.

```{r, handout = 0}
census_vars_doc <- read_html('https://api.census.gov/data/2017/acs/acs5/variables.html') %>% 
  html_node('table')

# This line takes a few moments to run.
census_vars <- html_table(census_vars_doc, fill = TRUE) 

head(census_vars)
```

===

We can use our data manipulation tools to search this unwieldy
documentation for variables of interest.

```{r, handout = 0}
library(tidyverse)

census_vars %>%
  set_tidy_names() %>%
  select(Name, Label) %>%
  filter(grepl('Median household income', Label))
  
```
